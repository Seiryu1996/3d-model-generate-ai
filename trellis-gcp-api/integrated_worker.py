#!/usr/bin/env python3
"""
Integrated Worker for TRELLIS Job Processing

This worker processes real jobs from the API queue system.
"""

import asyncio
import json
import sys
import os
import time
from datetime import datetime
import tempfile
import structlog
import redis
from enum import Enum
from typing import Dict, Any, Optional
from pathlib import Path

# Direct database access without complex imports

# Simple enum definitions
class JobStatus(str, Enum):
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"

class JobType(str, Enum):
    IMAGE_TO_3D = "image_to_3d"
    TEXT_TO_3D = "text_to_3d"

class IntegratedWorker:
    """Integrated worker that processes real API jobs."""
    
    def __init__(self):
        self.redis_client = None
        self.document_store = None
        self.logger = structlog.get_logger(__name__)
        self.job_queue = "trellis_jobs"
        
    async def start(self):
        """Start the worker process."""
        try:
            # Connect to Redis
            self.redis_client = redis.Redis(
                host='redis',
                port=6379,
                decode_responses=True
            )
            
            # Test Redis connection
            self.redis_client.ping()
            self.logger.info("Connected to Redis successfully")
            
            self.logger.info("Worker initialized - using simple approach")
            
            # Start processing loop
            await self.process_jobs_loop()
            
        except Exception as e:
            self.logger.error("Failed to start worker", error=str(e))
            raise
    
    async def process_jobs_loop(self):
        """Main job processing loop."""
        self.logger.info("üöÄ Integrated Worker started - processing real jobs...")
        
        while True:
            try:
                # Check for pending jobs in database
                pending_jobs = await self.get_pending_jobs()
                
                if pending_jobs:
                    self.logger.info(f"Found {len(pending_jobs)} pending jobs")
                    
                    # Process each job
                    for job in pending_jobs:
                        await self.process_job(job)
                else:
                    # No pending jobs, wait before next check
                    await asyncio.sleep(5)
                    
            except Exception as e:
                self.logger.error("Error in job processing loop", error=str(e))
                await asyncio.sleep(10)
    
    async def get_pending_jobs(self) -> list:
        """Get pending jobs from Redis queue (simplified approach)."""
        try:
            # For now, check if there are jobs in Redis queue
            job_keys = self.redis_client.keys("job:*")
            pending_jobs = []
            
            for key in job_keys:
                job_data = self.redis_client.hgetall(key)
                if job_data and job_data.get('status') == JobStatus.PENDING.value:
                    job_data['id'] = key.replace('job:', '')
                    pending_jobs.append(job_data)
            
            return pending_jobs
        except Exception as e:
            self.logger.error("Failed to get pending jobs from Redis", error=str(e))
            return []
    
    async def process_job(self, job_data: Dict[str, Any]):
        """Process a single job."""
        job_id = job_data.get('id')
        job_type = job_data.get('job_type')
        
        if not job_id or not job_type:
            self.logger.error("Invalid job data", job_data=job_data)
            return
        
        self.logger.info("üîÑ Processing job", job_id=job_id, job_type=job_type)
        
        try:
            # Update job status to processing
            await self.update_job_status(job_id, JobStatus.PROCESSING)
            await self.update_job_field(job_id, 'started_at', datetime.utcnow().isoformat())
            
            # Process based on job type
            if job_type == JobType.IMAGE_TO_3D.value:
                await self.process_image_to_3d_job(job_id, job_data)
            elif job_type == JobType.TEXT_TO_3D.value:
                await self.process_text_to_3d_job(job_id, job_data)
            else:
                raise ValueError(f"Unknown job type: {job_type}")
            
            # Mark job as completed
            await self.update_job_status(job_id, JobStatus.COMPLETED)
            await self.update_job_field(job_id, 'completed_at', datetime.utcnow().isoformat())
            await self.update_job_field(job_id, 'progress', 1.0)
            
            self.logger.info("‚úÖ Job completed successfully", job_id=job_id)
            
        except Exception as e:
            error_message = str(e)
            self.logger.error("‚ùå Job processing failed", job_id=job_id, error=error_message)
            
            # Mark job as failed
            await self.update_job_status(job_id, JobStatus.FAILED)
            await self.update_job_field(job_id, 'error_message', error_message)
    
    async def process_image_to_3d_job(self, job_id: str, job_data: Dict[str, Any]):
        """Process image-to-3D job (mock implementation)."""
        self.logger.info("üñºÔ∏è Processing image-to-3D job", job_id=job_id)
        
        # Simulate processing stages
        stages = [
            (0.1, "Loading image..."),
            (0.3, "Extracting features..."),
            (0.5, "Generating 3D mesh..."),
            (0.7, "Applying textures..."),
            (0.9, "Converting to GLB format...")
        ]
        
        for progress, message in stages:
            await self.update_job_field(job_id, 'progress', progress)
            self.logger.info("üìä Progress update", job_id=job_id, progress=progress, message=message)
            await asyncio.sleep(2)  # Simulate processing time
        
        # Generate mock output files
        output_files = [
            {
                "format": "glb",
                "url": f"https://storage.example.com/{job_id}/model.glb",
                "size_bytes": 1024000,
                "filename": f"{job_id}_model.glb"
            }
        ]
        
        await self.update_job_field(job_id, 'output_files', output_files)
    
    async def process_text_to_3d_job(self, job_id: str, job_data: Dict[str, Any]):
        """Process text-to-3D job (mock implementation)."""
        prompt = job_data.get('input_data', {}).get('prompt', 'Unknown prompt')
        self.logger.info("üìù Processing text-to-3D job", job_id=job_id, prompt=prompt)
        
        # Simulate processing stages
        stages = [
            (0.1, "Parsing text prompt..."),
            (0.2, "Generating initial concept..."),
            (0.4, "Creating 3D geometry..."),
            (0.6, "Refining mesh details..."),
            (0.8, "Applying materials..."),
            (0.9, "Exporting to formats...")
        ]
        
        for progress, message in stages:
            await self.update_job_field(job_id, 'progress', progress)
            self.logger.info("üìä Progress update", job_id=job_id, progress=progress, message=message)
            await asyncio.sleep(3)  # Simulate processing time
        
        # Generate mock output files
        output_files = [
            {
                "format": "glb",
                "url": f"https://storage.example.com/{job_id}/model.glb",
                "size_bytes": 1500000,
                "filename": f"{job_id}_model.glb"
            }
        ]
        
        await self.update_job_field(job_id, 'output_files', output_files)
    
    async def update_job_status(self, job_id: str, status: JobStatus):
        """Update job status in Redis."""
        try:
            self.redis_client.hset(f"job:{job_id}", "status", status.value)
            self.logger.info("Updated job status", job_id=job_id, status=status.value)
        except Exception as e:
            self.logger.error("Failed to update job status", job_id=job_id, status=status.value, error=str(e))
    
    async def update_job_field(self, job_id: str, field: str, value: Any):
        """Update a specific field in Redis job."""
        try:
            if isinstance(value, (dict, list)):
                value = json.dumps(value)
            self.redis_client.hset(f"job:{job_id}", field, str(value))
            self.logger.info("Updated job field", job_id=job_id, field=field)
        except Exception as e:
            self.logger.error("Failed to update job field", job_id=job_id, field=field, error=str(e))


async def main():
    """Main entry point."""
    
    # Setup logging
    structlog.configure(
        processors=[
            structlog.stdlib.filter_by_level,
            structlog.stdlib.add_logger_name,
            structlog.stdlib.add_log_level,
            structlog.stdlib.PositionalArgumentsFormatter(),
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.StackInfoRenderer(),
            structlog.processors.format_exc_info,
            structlog.processors.UnicodeDecoder(),
            structlog.processors.JSONRenderer()
        ],
        context_class=dict,
        logger_factory=structlog.stdlib.LoggerFactory(),
        wrapper_class=structlog.stdlib.BoundLogger,
        cache_logger_on_first_use=True,
    )
    
    print("üîó TRELLIS Integrated Worker Starting...")
    print("üìã This worker processes real jobs from the API")
    print("‚ö° Connected to Redis and Document Store")
    print("üîÑ Processing jobs from database...")
    
    worker = IntegratedWorker()
    await worker.start()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("üëã Worker stopped by user")
    except Exception as e:
        print(f"‚ùå Worker failed: {e}")
        sys.exit(1)